+++
date = 2018-03-28T00:00:00  # Schedule page publish date.

title = "Multimodal Deep Learning for Visually-Grounded Reasoning"
time_start = 2018-03-28T13:00:00
time_end = 2018-03-28T13:45:00
abstract = "Machine learning for computer vision and natural language processing accelerate the advancement of artificial intelligence. Since vision and natural language are the primary modalities of human interaction, understanding and reasoning based on both vision and natural language become a key challenge to machine intelligence. In this talk, the advances in multimodal deep learning models, multimodal residual networks (MRN), multimodal low-rank bilinear attention networks (MLB), and recently proposed bilinear attention networks (BAN), are explored for visual question answering tasks. To answer correctly, learning the joint representation of visual and linguistic information is critical to the models. We will discuss three essential principals, residual learning in multimodality, low-rank bilinear approximation, and a bilinear attention method, which considers every interaction of multimodal channels, to effectively and efficiently get a joint representation."
abstract_short = ""
event = "Google Tech Talk (Mountain View)"
event_url = ""
location = "Google Inc., Mountain View, CA, USA"

# Is this a selected talk? (true/false)
selected = true

# Projects (optional).
#   Associate this talk with one or more of your projects.
#   Simply enter the filename of your project file in `content/project/`.
#   Otherwise, set `projects = []`.
projects = []

# Links (optional).
url_pdf = ""
url_slides = ""
url_video = ""
url_code = ""

# Does the content use math formatting?
math = true

# Does the content use source code highlighting?
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = ""
caption = ""

+++

