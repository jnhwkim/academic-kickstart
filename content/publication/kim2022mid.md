+++
title = "Mutual Information Divergence: A Unified Metric for Multimodal Generative Models"

# Date first published.
date = "2022-05-27"

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Jin-Hwa Kim", "Yunji Kim", "Jiyoung Lee", "Kang Min Yoo", "Sang-Woo Lee"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference proceedings
# 2 = Journal
# 3 = Work in progress
# 4 = Technical report
# 5 = Book
# 6 = Book chapter
publication_types = ["1"]

# Publication name and optional abbreviated version.
publication = "In *Advances in Neural Information Processing Systems 35*"
publication_short = "In *NeurIPS*"

# Abstract and optional shortened version.
abstract = "Text-to-image generation and image captioning are recently emerged as a new experimental paradigm to assess machine intelligence. They predict continuous quantity accompanied by their sampling techniques in the generation, making evaluation complicated and intractable to get marginal distributions. Based on a recent trend that multimodal generative evaluations exploit a vison-and-language pre-trained model, we propose the negative Gaussian cross-mutual information using the CLIP features as a unified metric, coined by Mutual Information Divergence (MID). To validate, we extensively compare it with competing metrics using carefully-generated or human-annotated judgments in text-to-image generation and image captioning tasks. The proposed MID significantly outperforms the competitive methods by having consistency across benchmarks, sample parsimony, and robustness toward the exploited CLIP model. We look forward to seeing the underrepresented implications of the Gaussian cross-mutual information in multimodal representation learning and the future works based on this novel proposition."
abstract_short = ""

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = true

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter the filename (excluding '.md') of your project file in `content/project/`.
#   E.g. `projects = ["deep-learning"]` references `content/project/deep-learning.md`.
projects = []

# Links (optional).
url_pdf = "https://drive.google.com/file/d/13qDb9HAZkJSjWM6gckQ-KFomw1M8V45u/view?usp=sharing"
url_preprint = "http://arxiv.org/abs/2205.13445"
url_code = "https://github.com/naver-ai/mid.metric"
url_dataset = "https://github.com/naver-ai/mid.metric"
url_project = ""
url_slides = "https://drive.google.com/file/d/12p0ifSBTD6vbXHA14Rm9g141vuq6ieae/view?usp=sharing"
url_video = ""
url_poster = "https://drive.google.com/file/d/14dbLrT46f0UriBkj-dCZ2iJFSF_-f-_r/view?usp=sharing"
url_source = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Does the content use math formatting?
math = true

# Does the content use source code highlighting?
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = "kim2022thumb.png"
caption = ""

+++
